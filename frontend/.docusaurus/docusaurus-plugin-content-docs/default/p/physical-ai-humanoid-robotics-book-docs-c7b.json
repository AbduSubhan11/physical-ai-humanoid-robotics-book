{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Module 1: ROS2 Basics","items":[{"type":"link","href":"/physical-ai-humanoid-robotics-book/docs/module1_ros2","label":"Module 1 — The Robotic Nervous System (ROS 2)","docId":"module1_ros2","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin","items":[{"type":"link","href":"/physical-ai-humanoid-robotics-book/docs/module2_digital_twin","label":"Module 2 — The Digital Twin (Gazebo & Unity)","docId":"module2_digital_twin","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: AI Robot Brain","items":[{"type":"link","href":"/physical-ai-humanoid-robotics-book/docs/module3_ai_robot_brain","label":"The AI-Robot Brain (NVIDIA Isaac)","docId":"module3_ai_robot_brain","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision & Language Action","items":[{"type":"link","href":"/physical-ai-humanoid-robotics-book/docs/module4_vision_language_action","label":"Module 4 — Vision-Language-Action","docId":"module4_vision_language_action","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 5: Example Controllers","items":[{"type":"link","href":"/physical-ai-humanoid-robotics-book/docs/rclpy-example-controllers","label":"rclpy Example Controllers","docId":"rclpy-example-controllers","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"ROS2 Nodes","items":[{"type":"link","href":"/physical-ai-humanoid-robotics-book/docs/ros2-nodes","label":"ROS 2 Nodes","docId":"ros2-nodes","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Services","items":[{"type":"link","href":"/physical-ai-humanoid-robotics-book/docs/topics-services","label":"Topics & Services","docId":"topics-services","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"URDF for Humanoids","items":[{"type":"link","href":"/physical-ai-humanoid-robotics-book/docs/urdf-for-humanoids","label":"URDF for Humanoids","docId":"urdf-for-humanoids","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Final Capstone","items":[{"type":"link","href":"/physical-ai-humanoid-robotics-book/docs/final-capstone","label":"Final Capstone Project - Integrating Physical AI & Humanoid Robotics","docId":"final-capstone","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"final-capstone":{"id":"final-capstone","title":"Final Capstone Project - Integrating Physical AI & Humanoid Robotics","description":"Overview","sidebar":"tutorialSidebar"},"hardware_requirements":{"id":"hardware_requirements","title":"Hardware Requirements","description":"Essential hardware components for Physical AI & Humanoid Robotics projects."},"module1_ros2":{"id":"module1_ros2","title":"Module 1 — The Robotic Nervous System (ROS 2)","description":"The Robotic Operating System (ROS) is a flexible framework for writing robot software. It's a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behaviors across a wide variety of robotic platforms. ROS 2 is the latest iteration, designed with improved real-time capabilities, security, and multi-robot system support.","sidebar":"tutorialSidebar"},"module2_digital_twin":{"id":"module2_digital_twin","title":"Module 2 — The Digital Twin (Gazebo & Unity)","description":"Digital twins are virtual models designed to accurately reflect a physical object. In robotics, a digital twin allows for the simulation and testing of robots and their environments in a virtual space before deployment in the real world. This module explores two prominent platforms for creating digital twins in robotics: Gazebo and Unity.","sidebar":"tutorialSidebar"},"module3_ai_robot_brain":{"id":"module3_ai_robot_brain","title":"The AI-Robot Brain (NVIDIA Isaac)","description":"This module delves into the powerful NVIDIA Isaac platform, a comprehensive toolkit for robotics simulation, development, and deployment. We will explore its key components, including Isaac Sim for high-fidelity simulation, Isaac ROS for accelerating robotic applications, VSLAM for robust localization, Nav2 for advanced navigation, and techniques for generating photorealistic synthetic data.","sidebar":"tutorialSidebar"},"module4_vision_language_action":{"id":"module4_vision_language_action","title":"Module 4 — Vision-Language-Action","description":"This module explores the intersection of computer vision, natural language processing, and robotics. These domains converge to enable intuitive and capable robotic systems, allowing robots to understand human commands, interpret their environment, and execute complex actions.","sidebar":"tutorialSidebar"},"rclpy-example-controllers":{"id":"rclpy-example-controllers","title":"rclpy Example Controllers","description":"Implementing robotic control using rclpy.","sidebar":"tutorialSidebar"},"ros2-nodes":{"id":"ros2-nodes","title":"ROS 2 Nodes","description":"Understanding the fundamental building blocks of ROS 2.","sidebar":"tutorialSidebar"},"topics-services":{"id":"topics-services","title":"Topics & Services","description":"Exploring communication mechanisms in ROS 2.","sidebar":"tutorialSidebar"},"urdf-for-humanoids":{"id":"urdf-for-humanoids","title":"URDF for Humanoids","description":"Defining robotic structures with URDF.","sidebar":"tutorialSidebar"}}}}