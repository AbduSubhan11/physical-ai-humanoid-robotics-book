{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/physical-ai-humanoid-robotics-book/docs","tagsPath":"/physical-ai-humanoid-robotics-book/docs/tags","editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"D:\\Full-Stack Projects\\Physical-AI-Humanoid-Robotics-Book\\frontend\\sidebars.js","contentPath":"D:\\Full-Stack Projects\\Physical-AI-Humanoid-Robotics-Book\\frontend\\docs","docs":[{"id":"final-capstone","title":"Final Capstone Project - Integrating Physical AI & Humanoid Robotics","description":"Overview","source":"@site/docs/final_capstone.md","sourceDirName":".","slug":"/final-capstone","permalink":"/physical-ai-humanoid-robotics-book/docs/final-capstone","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/final_capstone.md","tags":[],"version":"current","frontMatter":{"id":"final-capstone","title":"Final Capstone Project - Integrating Physical AI & Humanoid Robotics"},"sidebar":"tutorialSidebar","previous":{"title":"URDF for Humanoids","permalink":"/physical-ai-humanoid-robotics-book/docs/urdf-for-humanoids"}},{"id":"hardware_requirements","title":"Hardware Requirements","description":"Essential hardware components for Physical AI & Humanoid Robotics projects.","source":"@site/docs/hardware_requirements.md","sourceDirName":".","slug":"/hardware-requirements","permalink":"/physical-ai-humanoid-robotics-book/docs/hardware-requirements","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/hardware_requirements.md","tags":[],"version":"current","frontMatter":{"title":"Hardware Requirements","description":"Essential hardware components for Physical AI & Humanoid Robotics projects.","slug":"/hardware-requirements"}},{"id":"module1_ros2","title":"Module 1 — The Robotic Nervous System (ROS 2)","description":"The Robotic Operating System (ROS) is a flexible framework for writing robot software. It's a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behaviors across a wide variety of robotic platforms. ROS 2 is the latest iteration, designed with improved real-time capabilities, security, and multi-robot system support.","source":"@site/docs/module1_ros2.md","sourceDirName":".","slug":"/module1_ros2","permalink":"/physical-ai-humanoid-robotics-book/docs/module1_ros2","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/module1_ros2.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","next":{"title":"Module 2 — The Digital Twin (Gazebo & Unity)","permalink":"/physical-ai-humanoid-robotics-book/docs/module2_digital_twin"}},{"id":"module2_digital_twin","title":"Module 2 — The Digital Twin (Gazebo & Unity)","description":"Digital twins are virtual models designed to accurately reflect a physical object. In robotics, a digital twin allows for the simulation and testing of robots and their environments in a virtual space before deployment in the real world. This module explores two prominent platforms for creating digital twins in robotics: Gazebo and Unity.","source":"@site/docs/module2_digital_twin.md","sourceDirName":".","slug":"/module2_digital_twin","permalink":"/physical-ai-humanoid-robotics-book/docs/module2_digital_twin","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/module2_digital_twin.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Module 1 — The Robotic Nervous System (ROS 2)","permalink":"/physical-ai-humanoid-robotics-book/docs/module1_ros2"},"next":{"title":"The AI-Robot Brain (NVIDIA Isaac)","permalink":"/physical-ai-humanoid-robotics-book/docs/module3_ai_robot_brain"}},{"id":"module3_ai_robot_brain","title":"The AI-Robot Brain (NVIDIA Isaac)","description":"This module delves into the powerful NVIDIA Isaac platform, a comprehensive toolkit for robotics simulation, development, and deployment. We will explore its key components, including Isaac Sim for high-fidelity simulation, Isaac ROS for accelerating robotic applications, VSLAM for robust localization, Nav2 for advanced navigation, and techniques for generating photorealistic synthetic data.","source":"@site/docs/module3_ai_robot_brain.md","sourceDirName":".","slug":"/module3_ai_robot_brain","permalink":"/physical-ai-humanoid-robotics-book/docs/module3_ai_robot_brain","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/module3_ai_robot_brain.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"The AI-Robot Brain (NVIDIA Isaac)","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Module 2 — The Digital Twin (Gazebo & Unity)","permalink":"/physical-ai-humanoid-robotics-book/docs/module2_digital_twin"},"next":{"title":"Module 4 — Vision-Language-Action","permalink":"/physical-ai-humanoid-robotics-book/docs/module4_vision_language_action"}},{"id":"module4_vision_language_action","title":"Module 4 — Vision-Language-Action","description":"This module explores the intersection of computer vision, natural language processing, and robotics. These domains converge to enable intuitive and capable robotic systems, allowing robots to understand human commands, interpret their environment, and execute complex actions.","source":"@site/docs/module4_vision_language_action.md","sourceDirName":".","slug":"/module4_vision_language_action","permalink":"/physical-ai-humanoid-robotics-book/docs/module4_vision_language_action","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/module4_vision_language_action.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Module 4 — Vision-Language-Action"},"sidebar":"tutorialSidebar","previous":{"title":"The AI-Robot Brain (NVIDIA Isaac)","permalink":"/physical-ai-humanoid-robotics-book/docs/module3_ai_robot_brain"},"next":{"title":"rclpy Example Controllers","permalink":"/physical-ai-humanoid-robotics-book/docs/rclpy-example-controllers"}},{"id":"rclpy-example-controllers","title":"rclpy Example Controllers","description":"Implementing robotic control using rclpy.","source":"@site/docs/rclpy-example-controllers.md","sourceDirName":".","slug":"/rclpy-example-controllers","permalink":"/physical-ai-humanoid-robotics-book/docs/rclpy-example-controllers","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/rclpy-example-controllers.md","tags":[],"version":"current","frontMatter":{"title":"rclpy Example Controllers","description":"Implementing robotic control using rclpy.","slug":"rclpy-example-controllers"},"sidebar":"tutorialSidebar","previous":{"title":"Module 4 — Vision-Language-Action","permalink":"/physical-ai-humanoid-robotics-book/docs/module4_vision_language_action"},"next":{"title":"ROS 2 Nodes","permalink":"/physical-ai-humanoid-robotics-book/docs/ros2-nodes"}},{"id":"ros2-nodes","title":"ROS 2 Nodes","description":"Understanding the fundamental building blocks of ROS 2.","source":"@site/docs/ros2-nodes.md","sourceDirName":".","slug":"/ros2-nodes","permalink":"/physical-ai-humanoid-robotics-book/docs/ros2-nodes","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/ros2-nodes.md","tags":[],"version":"current","frontMatter":{"title":"ROS 2 Nodes","description":"Understanding the fundamental building blocks of ROS 2.","slug":"ros2-nodes"},"sidebar":"tutorialSidebar","previous":{"title":"rclpy Example Controllers","permalink":"/physical-ai-humanoid-robotics-book/docs/rclpy-example-controllers"},"next":{"title":"Topics & Services","permalink":"/physical-ai-humanoid-robotics-book/docs/topics-services"}},{"id":"topics-services","title":"Topics & Services","description":"Exploring communication mechanisms in ROS 2.","source":"@site/docs/topics-services.md","sourceDirName":".","slug":"/topics-services","permalink":"/physical-ai-humanoid-robotics-book/docs/topics-services","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/topics-services.md","tags":[],"version":"current","frontMatter":{"title":"Topics & Services","description":"Exploring communication mechanisms in ROS 2.","slug":"topics-services"},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Nodes","permalink":"/physical-ai-humanoid-robotics-book/docs/ros2-nodes"},"next":{"title":"URDF for Humanoids","permalink":"/physical-ai-humanoid-robotics-book/docs/urdf-for-humanoids"}},{"id":"urdf-for-humanoids","title":"URDF for Humanoids","description":"Defining robotic structures with URDF.","source":"@site/docs/urdf-for-humanoids.md","sourceDirName":".","slug":"/urdf-for-humanoids","permalink":"/physical-ai-humanoid-robotics-book/docs/urdf-for-humanoids","draft":false,"unlisted":false,"editUrl":"https://github.com/abdusubhan11/physical-ai-humanoid-robotics-book/tree/main/frontend/docs/urdf-for-humanoids.md","tags":[],"version":"current","frontMatter":{"title":"URDF for Humanoids","description":"Defining robotic structures with URDF.","slug":"urdf-for-humanoids"},"sidebar":"tutorialSidebar","previous":{"title":"Topics & Services","permalink":"/physical-ai-humanoid-robotics-book/docs/topics-services"},"next":{"title":"Final Capstone Project - Integrating Physical AI & Humanoid Robotics","permalink":"/physical-ai-humanoid-robotics-book/docs/final-capstone"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"category","label":"Module 1: ROS2 Basics","items":[{"type":"doc","id":"module1_ros2"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin","items":[{"type":"doc","id":"module2_digital_twin"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: AI Robot Brain","items":[{"type":"doc","id":"module3_ai_robot_brain"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision & Language Action","items":[{"type":"doc","id":"module4_vision_language_action"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 5: Example Controllers","items":[{"type":"doc","id":"rclpy-example-controllers"}],"collapsed":true,"collapsible":true},{"type":"category","label":"ROS2 Nodes","items":[{"type":"doc","id":"ros2-nodes"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Services","items":[{"type":"doc","id":"topics-services"}],"collapsed":true,"collapsible":true},{"type":"category","label":"URDF for Humanoids","items":[{"type":"doc","id":"urdf-for-humanoids"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Final Capstone","items":[{"type":"doc","id":"final-capstone"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/physical-ai-humanoid-robotics-book/","source":"@site/src/pages/index.js"},{"type":"jsx","permalink":"/physical-ai-humanoid-robotics-book/auth/Login","source":"@site/src/pages/auth/Login.jsx"},{"type":"jsx","permalink":"/physical-ai-humanoid-robotics-book/auth/Signup","source":"@site/src/pages/auth/Signup.jsx"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"inject-env-plugin":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}